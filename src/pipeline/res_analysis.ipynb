{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e1a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import pandas\n",
    "import pandas\n",
    "from hyperparam_opt_wrapper import HyperparamOptimizerWrapper\n",
    "import json\n",
    "from hyperparameter_search_policies import opt_types\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b085a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"/workspace/results/[run]2025-2-20_12:18:54/\"\n",
    "result_files = os.listdir(FILE_PATH)\n",
    "result_paths = []\n",
    "for file in result_files:\n",
    "    result_paths.append(f\"{FILE_PATH}{file}\")\n",
    "FEATURE_NAMES = ['length_url', 'length_hostname', 'ip', 'nb_dots', 'nb_hyphens', 'nb_at', 'nb_qm', 'nb_and', 'nb_or', 'nb_eq', 'nb_underscore', 'nb_tilde', 'nb_percent', 'nb_slash', 'nb_star', 'nb_colon', 'nb_comma', 'nb_semicolumn', 'nb_dollar', 'nb_space', 'nb_www', 'nb_com', 'nb_dslash', 'http_in_path', 'https_token', 'ratio_digits_url', 'ratio_digits_host', 'punycode', 'port', 'tld_in_path', 'tld_in_subdomain', 'abnormal_subdomain', 'nb_subdomains', 'prefix_suffix', 'random_domain', 'shortening_service', 'path_extension', 'nb_redirection', 'nb_external_redirection', 'length_words_raw', 'char_repeat', 'shortest_words_raw', 'shortest_word_host', 'shortest_word_path', 'longest_words_raw', 'longest_word_host', 'longest_word_path', 'avg_words_raw', 'avg_word_host', 'avg_word_path', 'phish_hints', 'domain_in_brand', 'brand_in_subdomain', 'brand_in_path', 'suspecious_tld', 'statistical_report', 'whois_registered_domain', 'domain_registration_length', 'domain_age', 'web_traffic', 'dns_record', 'google_index', 'page_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1510c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_by_identifier(file_names, identifier):\n",
    "    remaining_file_names = []\n",
    "    selected_file_names = []\n",
    "    for file_name in file_names:\n",
    "        if identifier in file_name:\n",
    "            selected_file_names.append(file_name)\n",
    "        else:\n",
    "            remaining_file_names.append(file_name)\n",
    "    return selected_file_names, remaining_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980dabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_search_run_grid(data, axis=None):\n",
    "    if axis is None:\n",
    "        _, axis = plt.subplots(3, 2)\n",
    "        axis[0,0].set_title(\"probability difference\")\n",
    "        axis[0,1].set_title(\"total target probability\")\n",
    "        axis[1,0].set_title(\"gower distance\")\n",
    "        axis[1,1].set_title(\"constraint loss\")\n",
    "        axis[2,0].set_title(\"cost function\")\n",
    "\n",
    "    # prob_diff\n",
    "    axis[0,0].plot(data[\"step\"], data[\"prob_diff\"])\n",
    "\n",
    "    #total_node_prob\n",
    "    axis[0,1].plot(data[\"step\"], data[\"total_node_prob\"])\n",
    "\n",
    "    # gower_dist\n",
    "    axis[1,0].plot(data[\"step\"], data[\"gower_dist\"])\n",
    "\n",
    "    # const_loss\n",
    "    axis[1,1].plot(data[\"step\"], data[\"const_loss\"])\n",
    "\n",
    "    # cost_func\n",
    "    axis[2,0].plot(data[\"step\"], data[\"cost_func\"])\n",
    "\n",
    "    return axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872b42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_search_runs(logs, qualitative_samples = 2):\n",
    "    for log in logs:\n",
    "        with open(log, 'r') as file:\n",
    "            log_dict = json.load(file)\n",
    "        adversarial_id = log.split(\"/\")[-1].split(\"]\")[0][1:]\n",
    "        quali_printed = 0\n",
    "        while quali_printed < qualitative_samples:\n",
    "            search_data = log_dict[list(log_dict.keys())[quali_printed]]\n",
    "            plot_ax = update_search_run_grid(search_data)\n",
    "            plt.show(False)\n",
    "            plt.savefig(f\"{FILE_PATH}[{adversarial_id}]quali_search_plot_{quali_printed}\")\n",
    "            plt.close(\"all\")\n",
    "            quali_printed += 1\n",
    "        plot_ax = update_search_run_grid(log_dict[list(log_dict.keys())[0]])\n",
    "        for key in list(log_dict.keys())[1:]:\n",
    "            plot_ax = update_search_run_grid(log_dict[key], plot_ax)\n",
    "        plt.show(False)\n",
    "        plt.savefig(f\"{FILE_PATH}[{adversarial_id}]quanti_search_plot_lines\")   \n",
    "        plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb78737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_node_metrics(log_dict):\n",
    "    gower_dists = []\n",
    "    total_probs = []\n",
    "    prob_diffs = []\n",
    "    for key in log_dict.keys():\n",
    "        eval_func_search_trace = log_dict[key][\"cost_func\"]\n",
    "        best_idx = eval_func_search_trace.index(min(eval_func_search_trace))\n",
    "        gower_dists.append(log_dict[key][\"gower_dist\"][best_idx])\n",
    "        total_probs.append(log_dict[key][\"total_node_prob\"][best_idx])\n",
    "        prob_diffs.append(log_dict[key][\"prob_diff\"][best_idx])\n",
    "    return gower_dists, total_probs, prob_diffs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c550a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result_scatter(logs):\n",
    "    for log in logs:\n",
    "        with open(log, 'r') as file:\n",
    "            log_dict = json.load(file)\n",
    "        adversarial_id = log.split(\"/\")[-1].split(\"]\")[0][1:]\n",
    "        gower_dists, total_probs, prob_diffs = get_best_node_metrics(log_dict)\n",
    "        figure, axes = plt.subplots(1, 2)\n",
    "        axes[0].scatter(gower_dists, total_probs)\n",
    "        axes[0].set_title('gower by total probability')\n",
    "        axes[0].set_xlabel(\"gower dist\")\n",
    "        axes[0].set_ylabel(\"total prob\")\n",
    "        axes[1].scatter(gower_dists, prob_diffs)\n",
    "        axes[1].set_title('gower by probability change')\n",
    "        axes[1].set_xlabel(\"gower dist\")\n",
    "        axes[1].set_ylabel(\"prob diff\")\n",
    "        plt.show(False)\n",
    "        plt.savefig(f\"{FILE_PATH}[{adversarial_id}]quanti_search_plot_scatter\")   \n",
    "        plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8331f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_conf_mats(logs):\n",
    "    for log in logs:\n",
    "        with open(log, 'r') as file:\n",
    "            log_dict = json.load(file)\n",
    "        adversarial_id = log.split(\"/\")[-1].split(\"]\")[0][1:]\n",
    "        conf_mat_before = np.asarray(log_dict[\"before\"])\n",
    "        conf_mat_after = np.asarray(log_dict[\"after\"])\n",
    "        \n",
    "        before_disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat_before)\n",
    "        before_disp.plot()\n",
    "        plt.show(False)\n",
    "        plt.savefig(f\"{FILE_PATH}[{adversarial_id}]conf_mat_before\")   \n",
    "        plt.close(\"all\")\n",
    "\n",
    "        after_disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat_after)\n",
    "        after_disp.plot()\n",
    "        plt.show(False)\n",
    "        plt.savefig(f\"{FILE_PATH}[{adversarial_id}]conf_mat_after\")   \n",
    "        plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e254bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_search_logs_runs(file_names):\n",
    "    search_logs, remainder = select_by_identifier(file_names, \"search_logs\")\n",
    "    display_search_runs(search_logs)\n",
    "    return remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28dff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_search_logs_scatter(file_names):\n",
    "    search_logs, remainder = select_by_identifier(file_names, \"search_logs\")\n",
    "    display_result_scatter(search_logs)\n",
    "    return remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc9ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_conf_mats(file_names):\n",
    "    conf_mat_logs, remainder = select_by_identifier(file_names, \"confusion_matrices\")\n",
    "    display_conf_mats(conf_mat_logs)\n",
    "    return remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b1268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_analysis_metrics(feature_distance_tensors):\n",
    "    adj_feat_ratio_list = []\n",
    "    mean_adj_list = []\n",
    "    adj_var_list = []\n",
    "    adv_id_map = {}\n",
    "    tensor_idx = 0\n",
    "    for tensor_name in feature_distance_tensors:\n",
    "        feature_distance_tensor = t.load(tensor_name)\n",
    "        if \"]\" in tensor_name:\n",
    "            adversarial_id = tensor_name.split(\"/\")[-1].split(\"]\")[0][1:]\n",
    "        else:\n",
    "            identifier_list = tensor_name.split(\"/\")[-1].split(\"_\")\n",
    "            adversarial_id = f\"{identifier_list[0]}_{identifier_list[1]}\"\n",
    "        feat_adjusted_tensor = t.logical_not(t.eq(feature_distance_tensor, 0)).long()\n",
    "\n",
    "        adjusted_feature_counts = t.sum(feat_adjusted_tensor, dim=0)\n",
    "        adj_feat_ratio_list.append(t.div(adjusted_feature_counts, feature_distance_tensor.shape[0]))\n",
    "        mean_adj_list.append(t.mean(feature_distance_tensor, dim=0))\n",
    "        adj_var_list.append(t.var(feature_distance_tensor, dim=0))\n",
    "        adv_id_map[tensor_idx] = adversarial_id\n",
    "        tensor_idx += 1\n",
    "\n",
    "    adj_feat_ratios = t.cat(adj_feat_ratio_list, dim=0)\n",
    "    mean_adjs = t.cat(mean_adj_list, dim=0)\n",
    "    adj_vars = t.cat(adj_var_list, dim=0)\n",
    "    return adj_feat_ratios, mean_adjs, adj_vars, adv_id_map\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ef392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_avg_feat_analysis(results_dict):\n",
    "    avg_dict = {}\n",
    "    for entry_id in results_dict.keys():\n",
    "        local_dict = results_dict[entry_id]\n",
    "        for feature in local_dict.keys():\n",
    "            if feature not in avg_dict.keys():\n",
    "                avg_dict[feature] = {}\n",
    "            local_local_dict = local_dict[feature]\n",
    "            for metric in local_local_dict.keys():\n",
    "                if metric not in avg_dict[feature].keys():\n",
    "                    avg_dict[feature][metric] = []\n",
    "                avg_dict[feature][metric].append(results_dict[entry_id][feature][metric])\n",
    "    for feature in avg_dict.keys():\n",
    "        for metric in avg_dict[feature].keys():\n",
    "            avg_dict[feature][metric] = statistics.mean(avg_dict[feature][metric])\n",
    "    sortable_avg_dict = {}\n",
    "    for feature_name in avg_dict.keys():\n",
    "        if \"feat_name\" not in sortable_avg_dict.keys():\n",
    "            sortable_avg_dict[\"feat_name\"] = t.Tensor([feature_name])\n",
    "        else:\n",
    "            sortable_avg_dict[\"feat_name\"] = t.cat([sortable_avg_dict[\"feat_name\"], t.Tensor([feature_name])], dim=0)\n",
    "\n",
    "        for metric in avg_dict[feature_name].keys():\n",
    "            if metric not in sortable_avg_dict.keys():\n",
    "                sortable_avg_dict[metric] = t.Tensor([feature_name])\n",
    "            else:\n",
    "                sortable_avg_dict[metric] = t.cat([sortable_avg_dict[metric], t.Tensor([feature_name])], dim=0) \n",
    "\n",
    "    sort_idxs = t.argsort(sortable_avg_dict[\"feat_ratio\"])\n",
    "    for key in sortable_avg_dict.keys():\n",
    "        sortable_avg_dict[key] = sortable_avg_dict[key][sort_idxs]\n",
    "    \n",
    "    print(\"feat_name \\t adj_ratio \\t mean_dist \\t dist_var\")\n",
    "    for idx, feature_name in enumerate(sortable_avg_dict[\"feat_name\"]):\n",
    "        print(f\"{feature_name} \\t {round(sortable_avg_dict['feat_ratio'][idx],5)} \\t {round(sortable_avg_dict['mean_dist'][idx],5)} \\t {round(sortable_avg_dict['dist_var'][idx],5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31619f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_feature_analysis(file_names):\n",
    "    feature_distances, remainder = select_by_identifier(file_names, \"feat_dists\")\n",
    "    feat_ratios, mean_dists, dist_vars, adv_id_map = get_feature_analysis_metrics(feature_distances)\n",
    "    result_dict = {}\n",
    "    for idx in adv_id_map.keys():\n",
    "        adv_id = adv_id_map[idx]\n",
    "        sort_idxs = t.argsort(feat_ratios[idx])\n",
    "        feat_ratios_sorted = feat_ratios[idx][sort_idxs]\n",
    "        mean_dists_sorted = mean_dists[idx][sort_idxs]\n",
    "        dist_vars_sorted = dist_vars[idx][sort_idxs]\n",
    "        result_dict[adv_id] = {}\n",
    "        for feat_idx in range(len(sort_idxs)):\n",
    "            feat_ratio = feat_ratios_sorted[idx][feat_idx]\n",
    "            mean_dist = mean_dists_sorted[idx][feat_idx]\n",
    "            dist_var = dist_vars_sorted[idx][feat_idx]\n",
    "            feat_name = FEATURE_NAMES[feat_idx]\n",
    "            result_dict[adv_id][feat_name] = {\"feat_ratio\": feat_ratio, \"mean_dist\": mean_dist, \"dist_var\": dist_var}\n",
    "    result_dict_obj = json.dumps(result_dict)\n",
    "    with open(f\"{FILE_PATH}feature_adj_analysis\", \"w\") as outfile:\n",
    "        outfile.write(result_dict_obj)\n",
    "    print_avg_feat_analysis(result_dict)\n",
    "    return result_dict, remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901c82a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e7a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify(dataframe):\n",
    "    for key in dataframe.keys():\n",
    "        if not isinstance(dataframe[key], dict) and not isinstance(dataframe[key], list):\n",
    "            dataframe[key] = str(dataframe[key])\n",
    "        elif isinstance(dataframe[key], dict):\n",
    "            dataframe[key] = stringify(dataframe[key])\n",
    "        else:\n",
    "            dataframe[key] = [str(elem) for elem in dataframe[key]]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed3d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_result_pkl(result_pkl_path, results=True):\n",
    "    dictionary = pandas.read_pickle(result_pkl_path)\n",
    "    print(type(dictionary))\n",
    "    dictionary = stringify(dictionary)\n",
    "    if results:\n",
    "        with open(f\"{FILE_PATH}results.json\", \"w\") as outfile: \n",
    "            json.dump(dictionary, outfile)\n",
    "    else:\n",
    "        with open(f\"{FILE_PATH}configs.json\", \"w\") as outfile: \n",
    "            json.dump(dictionary, outfile)\n",
    "    print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50469b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_conf_mats(result_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_search_logs_runs(result_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1183a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_search_logs_scatter(result_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df06bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_result_pkl(f\"{FILE_PATH}results.pkl\")\n",
    "read_result_pkl(f\"{FILE_PATH}configs.pkl\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cf1f13b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 1 and 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result_dict, remainder \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_feature_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m print_avg_feat_analysis(result_dict)\n",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m, in \u001b[0;36mprocess_feature_analysis\u001b[0;34m(file_names)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_feature_analysis\u001b[39m(file_names):\n\u001b[1;32m      2\u001b[0m     feature_distances, remainder \u001b[38;5;241m=\u001b[39m select_by_identifier(file_names, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeat_dists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     feat_ratios, mean_dists, dist_vars, adv_id_map \u001b[38;5;241m=\u001b[39m \u001b[43mget_feature_analysis_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_distances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     result_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m adv_id_map\u001b[38;5;241m.\u001b[39mkeys():\n",
      "Cell \u001b[0;32mIn[24], line 23\u001b[0m, in \u001b[0;36mget_feature_analysis_metrics\u001b[0;34m(feature_distance_tensors)\u001b[0m\n\u001b[1;32m     20\u001b[0m     adv_id_map[tensor_idx] \u001b[38;5;241m=\u001b[39m adversarial_id\n\u001b[1;32m     21\u001b[0m     tensor_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 23\u001b[0m adj_feat_ratios \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_feat_ratio_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m mean_adjs \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mcat(mean_adj_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     25\u001b[0m adj_vars \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mcat(adj_var_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 1 and 2"
     ]
    }
   ],
   "source": [
    "result_dict, remainder = process_feature_analysis(result_paths)\n",
    "print_avg_feat_analysis(result_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
